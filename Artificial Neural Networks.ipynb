{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks\n",
    "\n",
    "KIAS CAC Summer School 2021\n",
    "\n",
    "Dates: 2021-7-12\n",
    "\n",
    "Author: Yung-Kyun Noh\n",
    "\n",
    "Department of Computer Science, Hanyang University / School of Computational Sciences, KIAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Structure\n",
    "\n",
    "<div>\n",
    "<img src=\"ANN.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective function with data $\\mathcal{D} = \\{\\mathbf{x}_i, y_i\\}_{i = 1}^N$ ($\\mathbf{x}\\in\\mathbb{R}^D, y_i\\in\\{1, 0\\}$):\n",
    "\\begin{eqnarray}\n",
    "L &=& \\frac{1}{2}\\sum_{i = 1}^N ||g(\\mathbf{x}_i) - y_i||^2\n",
    "\\end{eqnarray}\n",
    "with intermediate functions\n",
    "\\begin{eqnarray}\n",
    "g(\\mathbf{x}_i) &=& \\sigma\\left( \\sum_{j = 1}^{G_L} w_{L,j}g_{L,j}(\\mathbf{x}_i) - b \\right) \\\\\n",
    "\\vdots \\\\\n",
    "g_{l,k}(\\mathbf{x}_i) &=& \\sigma\\left(\\sum_{j = 1}^{G_{l - 1}} w_{l - 1, k, j}g_{l - 1, j}(\\mathbf{x}_i) - b_{l,k} \\right)\\\\\n",
    "\\vdots \\\\\n",
    "g_{1,k}(\\mathbf{x}_i) &=& \\sigma\\left(\\sum_{j = 1}^D w_{0,k,j}x_j - b_{1,k} \\right) \\\\\n",
    "\\sigma(t) &=& \\frac{1}{1 + \\exp(-t)}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_state(ax, W_arrays=np.array([]), bvals=np.array([]), title_str='Data'):\n",
    "    # function for scattering data and drawing classification boundary\n",
    "    # w0k^Tx - b > 0 or  w0k^Tx - b < 0\n",
    "    \n",
    "    # Scatter data points in 2-dimensional space\n",
    "    ax.scatter(data1[:,0], data1[:,1], label='class 1', c='red', alpha=.3)\n",
    "    ax.scatter(data2[:,0], data2[:,1], label='class 2', marker='^', c='blue', alpha=.3)\n",
    "    # set a title and labels\n",
    "    ax.set_title(title_str)\n",
    "    ax.legend()\n",
    "\n",
    "    if W_arrays.shape[0] != 0:\n",
    "        [x1min,x1max,x2min,x2max] = ax.axis()\n",
    "        x1vals = np.arange(x1min,x1max,0.1)\n",
    "        for i in range(W_arrays[0].shape[0]):\n",
    "            # zeros's layer, i-th nodes, 0-th or 1-th dimension\n",
    "            ax.plot(x1vals, (-W_arrays[0][i,0]*x1vals + bvals[1][i])/W_arrays[0][i,1], 'k')  # b[1] indicates b_1\n",
    "        ax.axis([x1min,x1max,x2min,x2max])\n",
    "        ax.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate mixture of Gaussians (class 1 & class 2)\n",
    "dim = 2\n",
    "datanum1_1 = 10\n",
    "datanum1_2 = 5\n",
    "datanum2_1 = 10\n",
    "datanum2_2 = 5\n",
    "datanum1 = datanum1_1 + datanum1_2\n",
    "datanum2 = datanum2_1 + datanum2_2\n",
    "mean1_1 = np.array([0, 0])\n",
    "mean1_2 = np.array([1, 1])\n",
    "mean2_1 = np.array([.5, .5])\n",
    "mean2_2 = np.array([0, -1])\n",
    "cov1_1 = np.array([[.01,0],[0,.2]])\n",
    "cov1_2 = np.array([[.1,.02],[.02,.1]])\n",
    "cov2_1 = np.array([[.02,0],[0,.2]])\n",
    "cov2_2 = np.array([[.1,-.01],[-.01,.05]])\n",
    "data1_1 = np.random.multivariate_normal(mean1_1, cov1_1, datanum1_1)\n",
    "data1_2 = np.random.multivariate_normal(mean1_2, cov1_2, datanum1_2)\n",
    "data2_1 = np.random.multivariate_normal(mean2_1, cov2_1, datanum2_1)\n",
    "data2_2 = np.random.multivariate_normal(mean2_2, cov2_2, datanum2_2)\n",
    "data1 = np.concatenate((data1_1, data1_2), axis=0)\n",
    "data2 = np.concatenate((data2_1, data2_2), axis=0)\n",
    "\n",
    "tstdatanum1_1 = 100\n",
    "tstdatanum1_2 = 100\n",
    "tstdatanum2_1 = 100\n",
    "tstdatanum2_2 = 100\n",
    "tstdata1_1 = np.random.multivariate_normal(mean1_1, cov1_1, tstdatanum1_1)\n",
    "tstdata1_2 = np.random.multivariate_normal(mean1_2, cov1_2, tstdatanum1_2)\n",
    "tstdata2_1 = np.random.multivariate_normal(mean2_1, cov2_1, tstdatanum2_1)\n",
    "tstdata2_2 = np.random.multivariate_normal(mean2_2, cov2_2, tstdatanum2_2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "draw_state(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "\\frac{dL}{dw_{l,k,j}} &=& \\sum_{i = 1}^N \\delta_{l + 1, k}(\\mathbf{x}_i) \\ g_{l + 1, k}(\\mathbf{x}_i)\\Big(1 - g_{l + 1, k}(\\mathbf{x}_i)\\Big)\\ g_{l,j}(\\mathbf{x}_i) \\\\\n",
    "\\delta_l:&& N \\times G_{l}, \\quad [\\delta_l]_{i,k} = \\delta_{l,k}(\\mathbf{x}_i) \\\\\n",
    "\\mathbf{G}_l:&& N \\times G_l, \\quad [G_l]_{i,k} = g_{l,k}(\\mathbf{x}_i) \\\\\n",
    "\\frac{dL}{d\\mathbf{W}_l}:&&G_{l + 1}\\times G_l \\\\\n",
    "l:&& 1,\\cdots,L \\quad (Index: 0,\\ldots,L-1)\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Structure\n",
    "\n",
    "<div>\n",
    "<img src=\"ANN2.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_arrays = []\n",
    "bs = []\n",
    "deltas = []\n",
    "init_var = .1\n",
    "\n",
    "# Hidden Layers\n",
    "num_nodes_per_layer = np.array([5,3])  # How many nodes in hidden layers (from the first to last layers)\n",
    "\n",
    "bs.append(np.zeros([2]))\n",
    "deltas.append(np.zeros([datanum1 + datanum2, dim]))\n",
    "\n",
    "numLayer = len(num_nodes_per_layer)\n",
    "for ilayer in range(numLayer):\n",
    "    bs.append(np.random.normal(0, init_var, num_nodes_per_layer[ilayer]))\n",
    "    deltas.append(np.zeros([datanum1 + datanum2, num_nodes_per_layer[ilayer]]))\n",
    "    if ilayer == 0:\n",
    "        W_arrays.append(np.random.normal(0, init_var, [num_nodes_per_layer[ilayer], dim]))\n",
    "    else:\n",
    "        W_arrays.append(np.random.normal(0, init_var, [num_nodes_per_layer[ilayer], num_nodes_per_layer[ilayer-1]]))\n",
    "W_arrays.append(np.random.normal(0, init_var, [1, num_nodes_per_layer[-1]])) # last layer\n",
    "bs.append(np.random.normal(0, init_var, 1))\n",
    "deltas.append(np.zeros([datanum1 + datanum2, 1]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "draw_state(ax, np.array(W_arrays, dtype=object), np.array(bs, dtype=object))\n",
    "\n",
    "print(bs[0].shape, bs[1].shape, bs[2].shape, bs[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_function(t):\n",
    "    # example: logistic_function(np.array([0,1,2]))\n",
    "    \n",
    "    ret_val = 1/(1 + np.exp(-t))\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_entropy_loss(labels, fs):\n",
    "    loss_val = np.sum(labels*np.log(fs) + (1 - labels)*np.log(1 - fs))\n",
    "    return loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gs(xs, W_arrays, bs):\n",
    "    # xs: datanum x dim\n",
    "    # W_arrays[l]: l-th layer x (l-1)-the layer\n",
    "    # bs[l]: l-th layer\n",
    "\n",
    "    for ilayer in range(len(W_arrays)):\n",
    "        if ilayer == 0:\n",
    "            ts = np.matmul(xs, W_arrays[0].T) - bs[1] # broadcast bs\n",
    "            gs = logistic_function(ts)\n",
    "        else:\n",
    "            ts = np.matmul(gs, W_arrays[ilayer].T) - bs[ilayer + 1] # broadcast bs\n",
    "            gs = logistic_function(ts)\n",
    "    return gs.T[0]  # final outputs of xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intermediate_gs(xs, W_arrays, bs):\n",
    "    # xs: datanum x dim\n",
    "    # W_arrays[l]: l-th layer x (l-1)-the layer\n",
    "    # bs[l]: l-th layer\n",
    "    \n",
    "    intermediate_gs = []\n",
    "    intermediate_gs.append(alldata)\n",
    "    for ilayer in range(len(W_arrays)):\n",
    "        if ilayer == 0:\n",
    "            ts = np.matmul(xs, W_arrays[0].T) - bs[1] # broadcast bs\n",
    "            gs = logistic_function(ts)\n",
    "            intermediate_gs.append(gs)\n",
    "        else:\n",
    "            ts = np.matmul(gs, W_arrays[ilayer].T) - bs[ilayer + 1] # broadcast bs\n",
    "            gs = logistic_function(ts)\n",
    "            intermediate_gs.append(gs)\n",
    "    return intermediate_gs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_loss(labels, gs):\n",
    "    loss = np.sum((labels - gs)**2)/len(labels)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((np.ones(datanum1), np.zeros(datanum2)))  # label of class 1: 1, label of class 2: 0\n",
    "alldata = np.concatenate((data1,data2), axis=0)\n",
    "intermediate_gs = get_intermediate_gs(alldata, W_arrays, bs)\n",
    "\n",
    "loss = get_mse_loss(labels, get_gs(np.concatenate((data1, data2), axis=0), W_arrays, bs))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "\\frac{dL}{dw_{l,k,j}} &=& \\sum_{i = 1}^N \\delta_{l + 1, k}(\\mathbf{x}_i) \\ g_{l + 1, k}(\\mathbf{x}_i)\\Big(1 - g_{l + 1, k}(\\mathbf{x}_i)\\Big)\\ g_{l,j}(\\mathbf{x}_i) \\\\\n",
    "\\delta_l:&& N \\times G_{l}, \\quad [\\delta_l]_{i,k} = \\delta_{l,k}(\\mathbf{x}_i) \\\\\n",
    "\\mathbf{G}_l:&& N \\times G_l, \\quad [G_l]_{i,k} = g_{l,k}(\\mathbf{x}_i) \\\\\n",
    "\\frac{dL}{d\\mathbf{W}_l}:&&G_{l + 1}\\times G_l \\\\\n",
    "l:&& 1,\\cdots,L  \\\\\n",
    "W_l:&& 0,\\cdots,L \n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epoch = 10000\n",
    "\n",
    "step_size = 1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "draw_state(ax, np.array(W_arrays, dtype=object), np.array(bs, dtype=object))\n",
    "\n",
    "for iepoch in range(num_epoch):\n",
    "    intermediate_gs = get_intermediate_gs(alldata, W_arrays, bs)\n",
    "\n",
    "    deltas[numLayer + 1] = (intermediate_gs[numLayer + 1] - np.array([labels]).T)\n",
    "\n",
    "    for ilayer in range(numLayer, -1,-1):\n",
    "        deltas[ilayer] = np.matmul(deltas[ilayer+1]*intermediate_gs[ilayer+1]*(1 - intermediate_gs[ilayer+1]), W_arrays[ilayer])\n",
    "\n",
    "    for ilayer in range(numLayer + 1):\n",
    "        W_arrays[ilayer] = W_arrays[ilayer] - \\\n",
    "            step_size*np.matmul((deltas[ilayer + 1]*intermediate_gs[ilayer + 1]*(1 - intermediate_gs[ilayer + 1])).T, \\\n",
    "            intermediate_gs[ilayer])\n",
    "        bs[ilayer + 1] = bs[ilayer + 1] - \\\n",
    "            np.sum(deltas[ilayer + 1]*intermediate_gs[ilayer + 1]*(1 - intermediate_gs[ilayer + 1]), axis=0)*(-1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "draw_state(ax, np.array(W_arrays, dtype=object), np.array(bs, dtype=object))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spacing = 0.025\n",
    "\n",
    "meshx = np.arange(-0.6, 1.7, spacing)\n",
    "meshy = np.arange(-1.8, 1.5, spacing)\n",
    "meshX, meshY = np.meshgrid(meshx, meshy)\n",
    "contourShape = meshX.shape\n",
    "print(contourShape)\n",
    "\n",
    "meshgridData = np.concatenate((meshX.reshape((-1,1)), meshY.reshape((-1,1))), axis=1)\n",
    "# print(meshgridData)\n",
    "\n",
    "Zs = get_gs(meshgridData, W_arrays, bs).reshape(contourShape)\n",
    "print(Zs.shape)\n",
    "\n",
    "levels = [0,.5,1]\n",
    "fig, ax = plt.subplots()\n",
    "CS = plt.contourf(meshX, meshY, Zs, levels, colors=('r', 'g'))\n",
    "\n",
    "draw_state(ax, np.array(W_arrays, dtype=object), np.array(bs, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_mse_loss(labels, get_gs(np.concatenate((data1, data2), axis=0), W_arrays, bs))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
