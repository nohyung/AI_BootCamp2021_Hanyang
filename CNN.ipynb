{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dee3b49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22ded177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n",
      "[5 0 4 ... 5 6 8] [7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b43e0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7ce0011cd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[82], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "370430e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) \n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# flatten (vectorize) for ANN\n",
    "x_train_flatten = x_train.reshape(60000, 784)\n",
    "x_test_flatten = x_test.reshape(10000, 784)\n",
    "\n",
    "num_categories = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_test = keras.utils.to_categorical(y_test, num_categories)\n",
    "\n",
    "print(y_train.shape, '\\n', y_train[0])    # one-hot coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d11dc4",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7e3d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(units = 512, activation='relu'))\n",
    "model.add(Dense(units = num_categories, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a6c6c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st layer: 401920\n",
      "2nd layer: 262656\n",
      "3rd layer: 5130\n"
     ]
    }
   ],
   "source": [
    "# number of the parameters in each layer\n",
    "print('1st layer:', (784 + 1)*512)  # 1: bias\n",
    "print('2nd layer:', (512 + 1)*512)\n",
    "print('3rd layer:', (512 + 1)*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b5cbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 7.0980 - accuracy: 0.8477 - val_loss: 0.4936 - val_accuracy: 0.9427\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5019 - accuracy: 0.9313 - val_loss: 0.4204 - val_accuracy: 0.9399\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3965 - accuracy: 0.9408 - val_loss: 0.3519 - val_accuracy: 0.9355\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3789 - accuracy: 0.9459 - val_loss: 0.3348 - val_accuracy: 0.9400\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3853 - accuracy: 0.9480 - val_loss: 0.6759 - val_accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_flatten, y_train,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_flatten, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62dda10",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3de9e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6535f06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 75)        750       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 58800)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                588010    \n",
      "=================================================================\n",
      "Total params: 588,760\n",
      "Trainable params: 588,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_categories, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59d79353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st layer: 750\n",
      "3rd layer: 588010\n"
     ]
    }
   ],
   "source": [
    "# number of the parameters in each layer\n",
    "print('1st layer:', (3*3 + 1)*75)  # 1: bias\n",
    "print('3rd layer:', (58800 + 1)*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2e176be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 13s 6ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0453 - val_accuracy: 0.9916\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0529 - val_accuracy: 0.9904\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0460 - val_accuracy: 0.9918\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0417 - val_accuracy: 0.9927\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0511 - val_accuracy: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ce4831340>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "x_train_conv = x_train.reshape(-1,28,28,1)\n",
    "x_test_conv = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "model.fit(x_train_conv, y_train, epochs=5, verbose=1, validation_data=(x_test_conv, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1e82f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "764b7d1a",
   "metadata": {},
   "source": [
    "### Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ec185f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 75)        750       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 75)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 50)        33800     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 25)          11275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 7, 25)          100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 256,867\n",
      "Trainable params: 256,567\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=num_categories, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df84c3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 15s 6ms/step - loss: 0.2698 - accuracy: 0.9189 - val_loss: 0.0667 - val_accuracy: 0.9813\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 0.0423 - val_accuracy: 0.9877\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0520 - accuracy: 0.9872 - val_loss: 0.0607 - val_accuracy: 0.9862\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 0.0354 - val_accuracy: 0.9904\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0383 - accuracy: 0.9908 - val_loss: 0.0615 - val_accuracy: 0.9847\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0352 - accuracy: 0.9916 - val_loss: 0.0484 - val_accuracy: 0.9884\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0329 - accuracy: 0.9922 - val_loss: 0.0632 - val_accuracy: 0.9858\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0285 - accuracy: 0.9929 - val_loss: 0.0467 - val_accuracy: 0.9893\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.0384 - val_accuracy: 0.9906\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0407 - val_accuracy: 0.9907\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0436 - val_accuracy: 0.9873\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0198 - accuracy: 0.9953 - val_loss: 0.0413 - val_accuracy: 0.9916\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 0.0431 - val_accuracy: 0.9914\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.0473 - val_accuracy: 0.9899\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0423 - val_accuracy: 0.9913\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.0449 - val_accuracy: 0.9900\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.0443 - val_accuracy: 0.9914\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0450 - val_accuracy: 0.9904\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0410 - val_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7cd00d6ca0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "x_train_conv = x_train.reshape(-1,28,28,1)\n",
    "x_test_conv = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "model.fit(x_train_conv, y_train, epochs=20, verbose=1, validation_data=(x_test_conv, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1deea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42787046",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da07b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images horizontally\n",
    "    vertical_flip=False, # Don't randomly flip images vertically\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "img_iter = datagen.flow(x_train_conv, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e94041fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0489 - val_accuracy: 0.9928\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0490 - val_accuracy: 0.9910\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0500 - val_accuracy: 0.9913\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0405 - val_accuracy: 0.9930\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0454 - val_accuracy: 0.9931\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0499 - val_accuracy: 0.9931\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0496 - val_accuracy: 0.9917\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0635 - val_accuracy: 0.9908\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0518 - val_accuracy: 0.9935\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0550 - val_accuracy: 0.9931\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0523 - val_accuracy: 0.9916\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0604 - val_accuracy: 0.9922\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0562 - val_accuracy: 0.9926\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0570 - val_accuracy: 0.9927\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0547 - val_accuracy: 0.9931\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0599 - val_accuracy: 0.9924\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0660 - val_accuracy: 0.9921\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0622 - val_accuracy: 0.9927\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0620 - val_accuracy: 0.9917\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0577 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7cd004ef10>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_conv, y_train, epochs=20, verbose=1, validation_data=(x_test_conv, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08204427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 1, 75)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABZCAYAAAAjOK9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAJlElEQVR4nO3dXYhU9xnH8e8zu64v2Rd1Fdes0Y01kWppUlGxFELSiyTNgt54kV70ol7Elhot9MLQiwqCF96UUlKoQhsIKMGwpZFiCCEUQi+q3Q0m7VYiVo2uqeBLsi+6u2b16cXO7Ix7pjtnzP/s7N/9fWBhXv77nGd/nnkYZ+bMMXdHRETilat1AyIi8vVokIuIRE6DXEQkchrkIiKR0yAXEYmcBrmISOTqsyg6d+5cb2xsDFLr1q1bQeoUtLS0BKkzMDDA8PCwpV2/ZMkS7+joCLLtixcvBqlTcPfu3WC1vvzyy+vuvjTNWjNzs9QRTqmuri5InYKxsbGQ5VJnsmjRIm9vbw+y0b6+viB1CtasWROsVk9PT+pMAFpaWnzZsmVBtt3Q0BCkTsHVq1eD1BkaGmJkZOSBHhCZDPLGxkZeeOGFILV6enqC1Cno7OwMUufIkSNVre/o6KC7uzvItnfs2BGkTsHAwECwWl1dXZ+lXWtmzJkzJ8h2m5ubg9QpuH79eshyqTNpb2/n7bffDrLRvXv3BqlTcPz48WC1zCx1JgDLli3j9ddfD7LtVatWBalTcPDgwSB1vk6+emlFRCRyGuQiIpHTIBcRiZwGuYhI5FINcjN70cw+NbNzZvZa1k3FYHR0FGVyv/y7999SJgnN2lcSlElAFQe5mdUBvwN+AKwDfmhm67JubCa7d+8eg4ODoEwmuDunT58GOIsymWwl2lcm5D/uqkwCSvOMfDNwzt3Pu/sd4C1gW7ZtzWxXr16lvr4eZVJ08+ZNHnnkEYA7yiRhVPtK0alTp0CZBJVmkLcDl0uu9+Vvm7WGhobI5e6LbtZnMjw8zIIFC0pvmvWZlLhTcnnW53LlyhVQJkGlGeTljjRKnI3CzF4xs24z6x4ZGfn6ncVnykyuXbtWi55qbcpMZvFJTe77w0szuXnzZq16mjb/5999yn2lv78/+8YilmaQ9wGPlVxfAXw+eZG7H3b3je6+cd68eaH6m5EaGxu5d+9e6U0VM1m6NPXRyFGaP38+t2/fLr2pYiahDs+PQOkx4YlcSjNZvHjx9HZWAytWrIAKmcD9uYT6ao2HVZpB/g/gCTN73MwagJeBcMfqRqitrY2xsTGUSdGiRYsYGhoCaFAmCfO0rxRt2rQJlElQFQe5u48Bu4D3gDPAMXfvzbqxmSyXy9HU1ATKZEIul+Ppp58GeBJlMtkltK9MqK+vB2USVKovzXL3E8CJjHuJyty5c3H3J2vdx0yyfPlygH+5+8Za9zLD9CuTBGUSkI7sFBGJnAa5iEjkNMhFRCKnQS4iErlMzhDU1NTEc889F6TW0aNHg9QpCHX2lXfeeaeq9ZcvX2bPnj1Btv3GG28EqVNw6NChYLW6urpSr3300UfZtWtXkO2uWxf2qzref//9YLWqObNNb29vsL/lwIEDQeoUnD9/Pmi9ajQ3N/P8888HqfXhhx8GqVMQ+vH4IPSMXEQkchrkIiKR0yAXEYmcBrmISOQ0yEVEIqdBLiISOQ1yEZHIaZCLiEROg1xEJHIa5CIikdMgFxGJnAa5iEjkNMhFRCKnQS4iEjkNchGRyGmQi4hEToNcRCRyGuQiIpHTIBcRiVwm5+xsaWmhs7MzSK0FCxYEqVMwPDwctF5aAwMDfPDBB0FqbdiwIUidgu3btwertXPnztRrGxoaWLlyZZDtbt26NUidgv7+/qD10uro6GDfvn1Bao2OjgapU3D8+PGg9apx6dIlXn311SC1Dh8+HKROweDgYJA6zzzzzAP/rp6Ri4hEToNcRCRyGuQiIpHTIBcRiVzFQW5mj5nZX83sjJn1mtme6WgsBsqk6MqVK2zbtg1gvTIpunHjBsCT2leKvvjiC1AmQaV5Rj4G/MLdvwlsAX5mZuuybSsOyqSorq6O/fv3A/SiTCbU1dUB9GlfKcrlcqBMgqo4yN39v+7+Uf7yIHAGaM+6sVgok3FtbW089dRTgDIptXDhQoDboFwKWlpaQJkEVdVr5GbWAXwHOJlJNxFSJknKpDzlkqRMwkg9yM2sEegCfu7uA2Xuf8XMus2sO/+64EOvmkzu3r07/Q3WRo6UmYQ6kCIGU+0ryqTyvlKrA/likWqQm9kcxgM/4u5/KrfG3Q+7+0Z339ja2hqyx5ksdSb510ofal999RXAN0iZSVNT07T2V0PGFPuKMqm8r8yfP396u4tMmk+tGPAH4Iy7/zr7lqKiTPLcnd27dwOMKJMidwdYhfaVCcokvDTPyL8H/Aj4vpmdzv+8lHFfsVAmeSdPnuTYsWMATcqk6OzZswCtaF+ZcOHCBVAmQVX80ix3/xvj/w2SSdz927XuYabYsmULN27coLW19d/uvrHW/cwUa9euBehRJkWrV68GZRKUjuwUEYmcBrmISOQ0yEVEIqdBLiISOQ1yEZHIWf4znWGLml0DPquwbAlwPfjGp89ad0999MYsyQSqyCVlJhB/LsokSY+fpKoyKZXJOTvdfWmlNWbWHfPHj8ysu5r1syETqC6XNJkUasacizJJ0uMnqdpMSumlFRGRyGmQi4hErpaD/HANtx1CFv3Hngkol3KUSZIySXrg/jN5s1NERKaPXloREYlc5oPczF40s0/N7JyZvVbmfjOz3+bv/8TMNmTdU1ppTjxtZs+aWX/Jt7j9KkVdZZL8nWgzAeVSjjJJyioT3D2zH6AO+A+wGmgAPgbWTVrzEvAu49+wuAU4mWVPVfa/HNiQv9wEnC3T/7PAX5TJ7M1EuSiTWmbi7pk/I98MnHP38+5+B3gL2DZpzTbgTR/3d2ChmS3PuK9UPJsTTyuTpKgzAeVSjjJJyiiTzAd5O3C55HofyabTrKk5m/oksd81s4/N7F0zW1+hlDJJemgyAeVSjjJJCphJNkd2lih3QorJH5NJs6ambOqTxH4ErHL3IRs/y8mfgSemKlfmNmWSFF0moFzKUSZJgTPJ/Bl5H/BYyfUVwOcPsKZmrMKJp919wN2H8pdPAHPMbMkUJZVJUvSZgHIpR5kkZZBJ5m921gPngccpvjGxftKaTu5/Y+JUlj1V2b8BbwK/mWJNG8XP428GLhWuK5PZkYlyUSa1zMTds31pxd3HzGwX8B7j7zb/0d17zewn+ft/D5xg/F3mc8Bt4MdZ9lSlwomn/2lmp/O3/RJYCRP9bwd+amZjwDDwsuf/BcpRJkkPQSagXMpRJknBMwEd2SkiEj0d2SkiEjkNchGRyGmQi4hEToNcRCRyGuQiIpHTIBcRiZwGuYhI5DTIRUQi9z8b+hVqL7hSmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the first five filters\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "print(filters.shape)\n",
    "plt.subplot(151)\n",
    "plt.imshow(filters[:,:,0,0], cmap='gray')\n",
    "plt.subplot(152)\n",
    "plt.imshow(filters[:,:,0,1], cmap='gray')\n",
    "plt.subplot(153)\n",
    "plt.imshow(filters[:,:,0,2], cmap='gray')\n",
    "plt.subplot(154)\n",
    "plt.imshow(filters[:,:,0,3], cmap='gray')\n",
    "plt.subplot(155)\n",
    "plt.imshow(filters[:,:,0,4], cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda17d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
