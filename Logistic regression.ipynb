{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "KIAS CAC Summer School 2021\n",
    "\n",
    "Dates: 2021-7-12\n",
    "\n",
    "Author: Yung-Kyun Noh\n",
    "\n",
    "Department of Computer Science, Hanyang University / School of Computational Sciences, KIAS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_state(wval, bval, title_str='Data'):\n",
    "    # function for scattering data and drawing classification boundary\n",
    "    # wx - b > 0 or  wx - b < 0\n",
    "    \n",
    "    # create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Scatter data points in 2-dimensional space\n",
    "    ax.scatter(data1[:,0], data1[:,1], label='class 1', c='red', alpha=.3)\n",
    "    ax.scatter(data2[:,0], data2[:,1], label='class 2', marker='^', c='blue', alpha=.3)\n",
    "    # set a title and labels\n",
    "    ax.set_title(title_str)\n",
    "    ax.legend()\n",
    "    \n",
    "    [x1min,x1max,x2min,x2max] = ax.axis()\n",
    "    x1vals = np.arange(x1min,x1max,0.1)\n",
    "    ax.plot(x1vals, (-wval[0]*x1vals + bval)/wval[1], 'k')\n",
    "    ax.axis([x1min,x1max,x2min,x2max])\n",
    "    ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_function(t):\n",
    "    # example: logistic_function(np.array([0,1,2]))\n",
    "    \n",
    "    ret_val = 1/(1 + np.exp(-t))\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(labels, fs):\n",
    "    loss_val = np.sum(labels*np.log(fs) + (1 - labels)*np.log(1 - fs))\n",
    "    return loss_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two Gaussians (class 1 & class 2)\n",
    "dim = 2\n",
    "datanum1 = 50\n",
    "datanum2 = 50\n",
    "mean1 = np.array([0, 0])\n",
    "mean2 = np.array([1, -.5])\n",
    "cov1 = np.array([[.1,.02],[.02,.1]])\n",
    "cov2 = np.array([[.1,.02],[.02,.1]])\n",
    "data1 = np.random.multivariate_normal(mean1, cov1, datanum1)\n",
    "data2 = np.random.multivariate_normal(mean2, cov2, datanum2)\n",
    "tstdatanum1 = 100\n",
    "tstdatanum2 = 100\n",
    "tstdata1 = np.random.multivariate_normal(mean1, cov1, tstdatanum1)\n",
    "tstdata2 = np.random.multivariate_normal(mean2, cov2, tstdatanum2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Bayes classifier\n",
    "\n",
    "When the data generating functions are Gaussians having the equivalent covariances, we can obtain the optimal linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal linear classifier\n",
    "optw = np.matmul(mean1 - mean2, np.linalg.inv(cov1))\n",
    "optb = np.matmul(optw, (mean1 + mean2)/2)\n",
    "print(optw, optb)\n",
    "\n",
    "draw_state(optw, optb, 'Data and optimal boundary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "w_init = np.random.normal(0,1,dim)\n",
    "b_init = np.random.normal(0,1,1)\n",
    "\n",
    "# extended w: [w, -b]\n",
    "extw = np.array([np.concatenate((w_init, -b_init))])\n",
    "# data with '1' is appended: [X, 1]\n",
    "extX = np.concatenate((np.concatenate((data1, data2), axis=0), \\\n",
    "                       np.ones([datanum1 + datanum2, 1])), axis=1)\n",
    "labels = np.concatenate((np.ones(datanum1), np.zeros(datanum2)))  # label of class 1: 1, label of class 2: 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_w(extw, extX, num_update=100, step_size=0.001, reg_const=1):\n",
    "    draw_state(extw[0,0:2], -extw[0,2], 'Before update')\n",
    "\n",
    "    objective_history = []\n",
    "    for i in range(num_update):\n",
    "        ts = np.matmul(extX, extw.T)  # w^TX\n",
    "        fs = logistic_function(ts)\n",
    "        extw = extw + step_size*(np.matmul(np.array([labels]) - fs.T, extX) - reg_const*extw)\n",
    "        objective_history.append(get_loss(labels, fs.T[0]))\n",
    "\n",
    "    draw_state(extw[0,0:2], -extw[0,2], 'Updated boundary')\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(objective_history)\n",
    "    ax.set_title(\"objective function\")\n",
    "    \n",
    "    return extw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extw = update_w(extw, extX, num_update=100, step_size=0.001, reg_const=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional 100 updates\n",
    "extw = update_w(extw, extX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After enough updates\n",
    "extw = update_w(extw, extX, num_update=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data with '1' is appended: [X, 1]\n",
    "extTstX = np.concatenate((np.concatenate((tstdata1, tstdata2), axis=0), \\\n",
    "                       np.ones([tstdatanum1 + tstdatanum2, 1])), axis=1)\n",
    "labels = np.concatenate((np.ones(tstdatanum1), np.zeros(tstdatanum2)))\n",
    "\n",
    "ts = np.matmul(extTstX, extw.T)  # w^TX\n",
    "err_rate = np.sum(np.abs((ts.T > 0) - np.array([labels])))/(tstdatanum1 + tstdatanum2)\n",
    "print(err_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
