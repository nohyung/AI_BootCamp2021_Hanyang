{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Discriminant Analysis\n",
    "\n",
    "KIAS CAC Summer School 2021\n",
    "\n",
    "Dates: 2021-7-12\n",
    "\n",
    "Author: Yung-Kyun Noh\n",
    "\n",
    "Department of Computer Science, Hanyang University / School of Computational Sciences, KIAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_state(wval, bval, title_str='Data'):\n",
    "    # function for scattering data and drawing classification boundary\n",
    "    # wx - b > 0 or  wx - b < 0\n",
    "    \n",
    "    # create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Scatter data points in 2-dimensional space\n",
    "    ax.scatter(data1[:,0], data1[:,1], label='class 1', c='red', alpha=.3)\n",
    "    ax.scatter(data2[:,0], data2[:,1], label='class 2', marker='^', c='blue', alpha=.3)\n",
    "    # set a title and labels\n",
    "    ax.set_title(title_str)\n",
    "    ax.legend()\n",
    "    \n",
    "    [x1min,x1max,x2min,x2max] = ax.axis()\n",
    "    x1vals = np.arange(x1min,x1max,0.1)\n",
    "    ax.plot(x1vals, (-wval[0]*x1vals + bval)/wval[1], 'k')\n",
    "    ax.axis([x1min,x1max,x2min,x2max])\n",
    "    ax.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate two Gaussians (class 1 & class 2)\n",
    "dim = 2\n",
    "datanum1 = 50\n",
    "datanum2 = 50\n",
    "mean1 = np.array([0, 0])\n",
    "mean2 = np.array([1, -.5])\n",
    "# mean2 = np.array([2, 2])\n",
    "cov1 = np.array([[.1,.02],[.02,.1]])\n",
    "cov2 = np.array([[.1,.02],[.02,.1]])\n",
    "data1 = np.random.multivariate_normal(mean1, cov1, datanum1)\n",
    "data2 = np.random.multivariate_normal(mean2, cov2, datanum2)\n",
    "tstdatanum1 = 100\n",
    "tstdatanum2 = 100\n",
    "tstdata1 = np.random.multivariate_normal(mean1, cov1, tstdatanum1)\n",
    "tstdata2 = np.random.multivariate_normal(mean2, cov2, tstdatanum2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optw = np.matmul(mean1 - mean2, np.linalg.inv(cov1))\n",
    "optb = np.matmul(optw, (mean1 + mean2)/2)\n",
    "print(optw, optb)\n",
    "\n",
    "draw_state(optw, optb, 'Data and optimal boundary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estMean1 = np.mean(data1, axis=0)\n",
    "estMean2 = np.mean(data2, axis=0)\n",
    "estCov1 = np.cov(data1.T, bias=True)\n",
    "estCov2 = np.cov(data2.T, bias=True)\n",
    "estS_W = datanum1/(datanum1 + datanum2)*estCov1 + datanum2/(datanum1 + datanum2)*estCov2  # Within-class covariance\n",
    "est_totCov = np.cov(np.concatenate((data1,data2),axis=0).T, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, we obtain $\\mathbf{w}$ maximizing the following objective function with $\\mathcal{D} = \\{\\mathbf{x}_i, y_i\\}_{i = 1}^N$, $\\mathbf{x}_i\\in\\mathbb{R}^D$, $y\\in\\{1,2\\}$:\n",
    "\\begin{eqnarray}\n",
    "L(\\mathbf{w}) = \\frac{\\mathbf{w}^\\top\\widehat{\\Sigma}\\mathbf{w}}{\\mathbf{w}^\\top \\widehat{S}_W\\mathbf{w}},\n",
    "\\end{eqnarray}\n",
    "where $\\Sigma$ is the total covariance matrix for all data, \n",
    "\\begin{eqnarray}\n",
    "\\widehat{\\Sigma} = \\sum_{i = 1}^N (\\mathbf{x}_i - \\widehat{\\mu})(\\mathbf{x}_i - \\widehat{\\mu})^\\top, \\quad \\widehat{\\mu} = \\sum_{i = 1}^N \\mathbf{x}_i,\n",
    "\\end{eqnarray}\n",
    "and $S_W$ is the within covariance matrix,\n",
    "\\begin{eqnarray}\n",
    "\\widehat{S}_W &=& \\frac{N_1}{N_1 + N_2}\\widehat{\\Sigma}_1 + \\frac{N_2}{N_1 + N_2}\\widehat{\\Sigma}_2, \\\\\n",
    "\\widehat{\\Sigma}_c &=& \\sum_{i;y_i = c} (\\mathbf{x}_i - \\widehat{\\mu}_c)(\\mathbf{x}_i - \\widehat{\\mu}_c)^\\top, \\quad \\widehat{\\mu}_c = \\sum_{i;y_i = c} \\mathbf{x}_i, \\quad c\\in\\{1,2\\}\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_vec = np.matmul(np.linalg.inv(estS_W), estMean1 - estMean2)\n",
    "b_val = np.matmul(w_vec, (estMean1 + estMean2)/2)\n",
    "\n",
    "draw_state(w_vec, b_val, 'Fisher Discriminant Analysis boundary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((np.ones(tstdatanum1), 2*np.ones(tstdatanum2)))\n",
    "gs = np.matmul(np.concatenate((tstdata1,tstdata2),axis=0), w_vec.T) - b_val  # discriminating function\n",
    "\n",
    "err_rate = (np.sum(labels[gs > 0] != 1) + np.sum(labels[gs < 0] != 2))/(tstdatanum1 + tstdatanum2)\n",
    "print(err_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
